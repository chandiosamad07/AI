{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7462f-8843-4977-92b3-b934817b858f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7704ee30-0367-4de0-a820-871cd0fc2093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (2.0.0)\n",
      "Requirement already satisfied: rich in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (13.9.2)\n",
      "Requirement already satisfied: namex in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (0.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->Keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->Keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->Keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->Keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dae535e-c2da-4b0f-9877-b5a1183f5ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\abdul.samad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd91c102-15c9-4447-8e96-11e127c79e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33acaa7d-83e0-4f1b-b8f0-ad8afc939c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97763449-3198-4b44-b5a5-c3c95a05cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb470402-5415-4e01-bbcc-1f4e26910c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bead87-bca6-4e90-b21f-698bee880188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b0f4b5-1f81-4b4e-b308-4ddaa83d00af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels),(test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b864c1f6-d610-46be-9d71-3bc415d53192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53cb1109-90b5-4043-b646-8640c4a0ea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d2b973-32d0-4c74-b82f-527961c04fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54833fa8-de6e-442d-921a-643b40c98897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models,layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2db46af5-728b-4123-8179-87882575e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul.samad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512 , activation='relu',input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10 , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1023b2b4-b1a8-43fd-a52a-e0ea545b5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0210057c-be00-4eec-a4d5-c0d89c1b5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1c0031-f088-485c-bcde-6e5c29d24ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "400bf4b5-d9d5-46c2-8dd8-5949b9975587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13950e0c-9dcb-4a40-9058-1a3195160172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b8613c-a74b-4983-9eb3-77a9569bf83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8744 - loss: 0.4377\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.1206\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0740\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9850 - loss: 0.0511\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 0.0386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2862f11d010>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f63a636-3574-4295-bd78-0457800742d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0684\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e0fdc17-ea8b-431e-9185-130c24f60371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9815000295639038\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01926504-5bee-413f-8b57-3554f2721173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4873 - val_accuracy: 0.9570 - val_loss: 0.1441\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1168 - val_accuracy: 0.9690 - val_loss: 0.1074\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9766 - loss: 0.0746 - val_accuracy: 0.9682 - val_loss: 0.1087\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0549 - val_accuracy: 0.9737 - val_loss: 0.0923\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0427 - val_accuracy: 0.9728 - val_loss: 0.0991\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.98\n",
      "Model saved as 'mnist_model.h5'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize input data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Flatten 28x28 images into 1D array\n",
    "    Dense(128, activation='relu'),  # First hidden layer with 128 neurons\n",
    "    Dense(64, activation='relu'),   # Second hidden layer with 64 neurons\n",
    "    Dense(10, activation='softmax') # Output layer with 10 neurons for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('mnist_model.h5')\n",
    "print(\"Model saved as 'mnist_model.h5'\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29d76066-584b-4ddc-8b11-99c9e51c3dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Predicted Digit: 3\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess a custom handwritten image\n",
    "image_path = 'three.png'  # Replace with your image path\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "\n",
    "# Preprocess the image: resize, normalize, and reshape\n",
    "img_resized = cv2.resize(img, (28, 28))  # Resize to 28x28 pixels\n",
    "img_normalized = img_resized / 255.0  # Normalize pixel values to [0, 1]\n",
    "img_reshaped = img_normalized.reshape(1, 28, 28)  # Reshape to (1, 28, 28)\n",
    "\n",
    "# Visualize the preprocessed image\n",
    "plt.imshow(img_resized, cmap='gray')\n",
    "plt.title(\"Preprocessed Image\")\n",
    "plt.show()\n",
    "\n",
    "# Predict the digit using the trained model\n",
    "model = tf.keras.models.load_model('mnist_model.h5')  # Load the saved model\n",
    "predictions = model.predict(img_reshaped)\n",
    "predicted_digit = np.argmax(predictions)\n",
    "\n",
    "print(f\"Predicted Digit: {predicted_digit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0df1d-251a-4e07-94bb-80218beb0e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
